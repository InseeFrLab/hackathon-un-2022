{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b21118b-69af-44a0-8917-3cdb17521230",
   "metadata": {},
   "source": [
    "# Choose a Kernel\n",
    "- Please wait 4-5 minutes for the kernel to initialize properly\n",
    "- Keep checking kernel status at the bottom (changes from Initializing to Idle state)\n",
    "- Rename notebook and start coding ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ad908-33ac-4d0d-b962-e08fe1e1200c",
   "metadata": {},
   "source": [
    "# Reading AIS Data\n",
    "- write your own code to access AIS data (might show you in Workshop) or\n",
    "- Import AIS package from GitLab (recommended) \n",
    "    - get_ais()\n",
    "    - access GitLab using a username and token (shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdbe9538-2b10-4452-9e9a-12245df8b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/sparkuser/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Collecting pyarrow==10.0.0\n",
      "  Downloading pyarrow-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 35.3 MB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3fs\n",
      "  Downloading s3fs-2022.10.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.8/site-packages (from pyarrow==10.0.0) (1.20.1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 71.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec==2022.10.0\n",
      "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 76.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiobotocore~=2.4.0\n",
      "  Downloading aiobotocore-2.4.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 59.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.10.10\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 73.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting botocore<1.27.60,>=1.27.59\n",
      "  Downloading botocore-1.27.59-py3-none-any.whl (9.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1 MB 73.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (21.2.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[K     |████████████████████████████████| 262 kB 93.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 98.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 80.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing_extensions>=4.0\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs) (1.15.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.10)\n",
      "Installing collected packages: multidict, frozenlist, yarl, typing-extensions, jmespath, charset-normalizer, async-timeout, aiosignal, wrapt, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs, pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 3.0.0\n",
      "    Uninstalling pyarrow-3.0.0:\n",
      "      Successfully uninstalled pyarrow-3.0.0\n",
      "Successfully installed aiobotocore-2.4.0 aiohttp-3.8.3 aioitertools-0.11.0 aiosignal-1.2.0 async-timeout-4.0.2 botocore-1.27.59 charset-normalizer-2.1.1 frozenlist-1.3.1 fsspec-2022.10.0 jmespath-1.0.1 multidict-6.0.2 pyarrow-10.0.0 s3fs-2022.10.0 typing-extensions-4.4.0 wrapt-1.14.1 yarl-1.8.1\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow==10.0.0 s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f376b0-9fa0-43c3-8207-406b69441044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allow multiple outputs in one jupyter cell\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# to apply aggregation functions on spark df\n",
    "import pyspark.sql.functions as F\n",
    "from pyarrow import fs\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d959cca8-a285-42fd-8d79-112098db89d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git\n",
      "  Cloning https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git to /tmp/pip-req-build-dhxote0v\n",
      "Building wheels for collected packages: ais\n",
      "  Building wheel for ais (setup.py): started\n",
      "  Building wheel for ais (setup.py): finished with status 'done'\n",
      "  Created wheel for ais: filename=ais-2.7.6-py3-none-any.whl size=9267 sha256=9a450da562a289146a720fc0e4ab4abcdfaf86ae63e929115c3e0579c5b47422\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dgz0_i43/wheels/49/e0/a2/25d96a62cf626776ab2fd57fcbd822c2b8118049a84b16953d\n",
      "Successfully built ais\n",
      "Installing collected packages: ais\n",
      "Successfully installed ais-2.7.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this cell contains the code to access GitLab repo\n",
    "# need it to install ais package from GitLab repo\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "GITLAB_USER = \"read_aistt\"  # read only access\n",
    "GITLAB_TOKEN = \"MMQ6ky1rnLsuKxjyZuvB\"\n",
    "\n",
    "# clone the repo and install the ais packag\n",
    "git_package = f\"git+https://{GITLAB_USER}:{GITLAB_TOKEN}@code.officialstatistics.org/trade-task-team-phase-1/ais.git\"\n",
    "\n",
    "std_out = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", git_package], capture_output=True, text=True).stdout\n",
    "print(std_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2aeda2e-a093-405b-ad10-40726776d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "AWS_ACCESS_KEY_ID ····················\n",
      "AWS_SECRET_ACCESS_KEY ········································\n",
      "AWS_SESSION_TOKEN ··········································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "AWS_ACCESS_KEY_ID=getpass.getpass(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY=getpass.getpass(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_SESSION_TOKEN=getpass.getpass(\"AWS_SESSION_TOKEN\")\n",
    "AWS_S3_ENDPOINT=\"minio.lab.sspcloud.fr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91762ff2-4f2f-41ab-bfc4-276cd465b6d7",
   "metadata": {},
   "source": [
    "# Using get_ais()\n",
    "- retrieve data for a single date\n",
    "- filter data on date and specific columns\n",
    "- filter data for a range of dates\n",
    "- filter data based on mmsi (unique ship identifier)\n",
    "- fiter data based on a geographical polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c739f75-5735-495b-81ef-71d4a4fe2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import get_ais() from ais package\n",
    "from ais import functions as af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48a59d-5bbd-4b48-a274-af8f91dba182",
   "metadata": {},
   "source": [
    "### Example 5: Filter data based on geolocation polygon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d0c5ea-79b9-4fa8-9c60-09900e25c8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0maf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolygon_to_hex_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpolygons\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhex_resolution\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moverfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "A wrapper for h3.polyfill that returns integer hex ids for multiple polygons.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "polygons: list of tuples\n",
       "    the first element in this tuple is expected to be a (name) string\n",
       "    identifier for the polygon and the second element is the polygon itself (see example above)\n",
       "    \n",
       "hex_resolution: int, default 8\n",
       "    the resolution of the hexagons to fill the input polygon with. Default is 8, a hex with an avg area of 0.737 sq km. \n",
       "    A polygon with an area of 100 sq. km will contain ~136 resolution 8 hexes. The same 100 sq. km polygon \n",
       "    can be approximated by ~949 hexes using resolution 9. Note that the higher the resolution, the higher \n",
       "    the polygon area covered by the hexes. However, a small increase in resolution dramatically increases\n",
       "    the number of hexes. See https://h3geo.org/docs/core-library/restable/ for a table of hex resolutions.\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "Dataframe with the following columns:\n",
       "    - hex_id: the h3 hex ids (64-bit ints)\n",
       "    - polygon_name: the name of the polygon\n",
       "    - hex_resolution: the resolution of the hex\n",
       "    \n",
       ">>>hull_bbox = {\n",
       "    \"type\": \"Polygon\",\n",
       "    \"coordinates\": [\n",
       "        [\n",
       "            [-0.3169, 53.7344],\n",
       "            [-0.2537, 53.7344],\n",
       "            [-0.2537, 53.75],\n",
       "            [-0.3169, 53.75],\n",
       "            [-0.3169, 53.7344]\n",
       "        ]\n",
       "    ]\n",
       "}\n",
       ">>>london_bbox = {\n",
       "    \"type\": \"Polygon\",\n",
       "    \"coordinates\": [\n",
       "        [\n",
       "            [-0.1203, 51.4415],\n",
       "            [0.5869, 51.4415],\n",
       "            [0.5869, 51.5262],\n",
       "            [-0.1203, 51.5262],\n",
       "            [-0.1203, 51.4415]\n",
       "        ]\n",
       "    ]\n",
       "}\n",
       ">>>query_polys = [(\"HullPortArea\", hull_bbox),(\"LondonPortArea\", london_bbox)]\n",
       ">>>polygon_to_hex_df(query_polys, 10)\n",
       "                   hex_id    polygon_name  hex_resolution\n",
       "0      621940969126789119    HullPortArea              10\n",
       "1      621940969212772351    HullPortArea              10\n",
       "2      621940969214869503    HullPortArea              10\n",
       "3      621940974334017535    HullPortArea              10\n",
       "4      621940969137274879    HullPortArea              10\n",
       "                   ...             ...             ...\n",
       "34427  621941942979756031  LondonPortArea              10\n",
       "34428  621941942943285247  LondonPortArea              10\n",
       "34429  621941942854713343  LondonPortArea              10\n",
       "34430  621941942818242559  LondonPortArea              10\n",
       "34431  621941940535295999  LondonPortArea              10\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.8/site-packages/ais/_poly.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first this function and then pass on its output with get_ais()\n",
    "af.polygon_to_hex_df?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fec282-d583-4e78-bc16-99388ca1bd40",
   "metadata": {},
   "source": [
    "![alternatvie text](https://drive.google.com/uc?export=view&id=1PxMJuKiC5Wi1a7WH0yCWXpG9sajLPdXa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2966a0bb-3da6-4dc2-8b72-51869ba239c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2nd parameter for polygon_to_hex_df() \n",
    "    #\thttps://boundingbox.klokantech.com/\n",
    "# polygon coordinates in geojson format\n",
    "\n",
    "AREA = \"azov_black\"\n",
    "\n",
    "if AREA == \"azov\":\n",
    "    bb = [[32.4143284746,45.0048840974],[40.0827855058,45.0048840974],[40.0827855058,47.9395951189],[32.4143284746,47.9395951189],[32.4143284746,45.0048840974]]\n",
    "elif AREA == \"azov_black\":\n",
    "    bb = [[43.3308500839,39.9913666442],[26.1506878922,41.33737686],[27.1872912828,48.4341912681],[44.3674534746,47.2431326615],[43.3308500839,39.9913666442]]\n",
    "\n",
    "polygon = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [bb]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461923d8-4108-4bd5-bb2c-f75aba1650ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first parameter for polygon_to_hex_df() is the name/label for the polygon\n",
    "polygon_hex_df = af.polygon_to_hex_df([(\"Polygon\", polygon)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d01ab34-4a26-4edc-8dcc-87bcb3a711a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1543295"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime.fromisoformat(\"2022-01-01\")\n",
    "end_date = datetime.fromisoformat(\"2022-01-07\")\n",
    "columns = [\"mmsi\", \"latitude\", \"longitude\", \"eeid\", \"dt_insert_utc\", \"destination\"]\n",
    "\n",
    "# pass polygon_hex_df to get_ais()\n",
    "df = af.get_ais(spark,\n",
    "                start_date, \n",
    "                end_date = end_date,\n",
    "                columns = columns,\n",
    "                polygon_hex_df = polygon_hex_df\n",
    "               )\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8b11f0-ce60-443f-a453-a684905c9b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+---------+-----------+-------------------+------------------+-----------+-------------------+------------+\n",
      "|hex_resolution|  longitude|     mmsi|destination|               eeid|    H3_int_index_8|   latitude|      dt_insert_utc|polygon_name|\n",
      "+--------------+-----------+---------+-----------+-------------------+------------------+-----------+-------------------+------------+\n",
      "|             8|31.40833333|272157700|   MYKOLAIV|5191743282127358980|613021963599740927|47.52666667|2022-01-01 05:58:49|     Polygon|\n",
      "|             8|31.33166667|272157700|   MYKOLAIV|5191743282127358980|613021966030340095|     47.535|2022-01-01 18:25:52|     Polygon|\n",
      "|             8|31.33166667|272157700|   MYKOLAIV|5191743282127358980|613021966030340095|     47.535|2022-01-01 21:14:30|     Polygon|\n",
      "|             8|31.33333333|272157700|   MYKOLAIV|5191743282127358980|613021966030340095|     47.535|2022-01-01 07:46:57|     Polygon|\n",
      "|             8|31.33333333|272157700|   MYKOLAIV|5191743282127358980|613021966030340095|     47.535|2022-01-01 09:43:50|     Polygon|\n",
      "+--------------+-----------+---------+-----------+-------------------+------------------+-----------+-------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ais messages captured in the Colombo port region\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7a1b2c-7abb-4b99-b794-8d55adf0db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_str = start_date.strftime(\"%Y%M%d\")\n",
    "end_date_str = end_date.strftime(\"%Y%M%d\")\n",
    "\n",
    "s3 = fs.S3FileSystem(endpoint_override=AWS_S3_ENDPOINT,\n",
    "                     access_key=AWS_ACCESS_KEY_ID, \n",
    "                     secret_key=AWS_SECRET_ACCESS_KEY, \n",
    "                     session_token=AWS_SESSION_TOKEN)\n",
    "table = pa.Table.from_pandas(df.toPandas())\n",
    "pq.write_table(table, f\"projet-hackathon-un-2022/AIS/ais_{AREA}_{start_date_str}_{end_date_str}.parquet\", filesystem=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d62901-5e39-450e-8f35-8fb3c949cba4",
   "metadata": {},
   "source": [
    "# Accessing IHS Data \n",
    "- ship registry data in s3\n",
    "- includes details about ship on a very granular level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3879e5a-43d6-4ecd-806d-c6350a3029e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': AWS_S3_ENDPOINT},\n",
    "                       key=AWS_ACCESS_KEY_ID, \n",
    "                       secret=AWS_SECRET_ACCESS_KEY\n",
    "                       token=AWS_SESSION_TOKEN)\n",
    "BUCKET_OUT = \"projet-hackathon-un-2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf004cf-8018-4b77-8eba-6f5d1ef48f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"s3a://ungp-ais-data-historical-backup/register/\"\n",
    "\n",
    "# first file \n",
    "df_ship_data = spark.read.load(basepath+ \"ShipData.CSV\", \n",
    "                               format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9de59143-5127-4097-81e2-2fd158618c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ship_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12854537-9ed2-4ab7-a5dc-53835aa2bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ShipData.CSV (few cols) .....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(246724, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StatCode5</th>\n",
       "      <th>MaritimeMobileServiceIdentityMMSINumber</th>\n",
       "      <th>ShipStatusEffectiveDate</th>\n",
       "      <th>ShiptypeLevel5</th>\n",
       "      <th>LRIMOShipNo</th>\n",
       "      <th>FuelConsumptionTotal</th>\n",
       "      <th>GrossTonnage</th>\n",
       "      <th>NetTonnage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X11A2YP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19610000</td>\n",
       "      <td>Yacht</td>\n",
       "      <td>1000019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>551</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X11A2YP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19951000</td>\n",
       "      <td>Yacht</td>\n",
       "      <td>1000021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X11A2YP</td>\n",
       "      <td>234028000.0</td>\n",
       "      <td>19950512</td>\n",
       "      <td>Yacht</td>\n",
       "      <td>1000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X11A2YP</td>\n",
       "      <td>239488000.0</td>\n",
       "      <td>19950429</td>\n",
       "      <td>Yacht</td>\n",
       "      <td>1000045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X11A2YP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20220601</td>\n",
       "      <td>Yacht</td>\n",
       "      <td>1000057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StatCode5  MaritimeMobileServiceIdentityMMSINumber  ShipStatusEffectiveDate  \\\n",
       "0   X11A2YP                                      NaN                 19610000   \n",
       "1   X11A2YP                                      NaN                 19951000   \n",
       "2   X11A2YP                              234028000.0                 19950512   \n",
       "3   X11A2YP                              239488000.0                 19950429   \n",
       "4   X11A2YP                                      NaN                 20220601   \n",
       "\n",
       "  ShiptypeLevel5  LRIMOShipNo  FuelConsumptionTotal  GrossTonnage  NetTonnage  \n",
       "0          Yacht      1000019                   0.0           551         165  \n",
       "1          Yacht      1000021                   0.0          1980         588  \n",
       "2          Yacht      1000033                   0.0           178          53  \n",
       "3          Yacht      1000045                   0.0           264          79  \n",
       "4          Yacht      1000057                   0.0           234          70  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select only relevant cols from spark df\n",
    "print('Loading ShipData.CSV (few cols) .....')\n",
    "ship_data = df_ship_data.select(\"StatCode5\", \"MaritimeMobileServiceIdentityMMSINumber\", \"ShipStatusEffectiveDate\",\n",
    "                               \"ShiptypeLevel5\", \"LRIMOShipNo\", \"FuelConsumptionTotal\", \"GrossTonnage\", \"NetTonnage\").toPandas()\n",
    "\n",
    "ship_data.shape\n",
    "ship_data.head()\n",
    "\n",
    "FILE_KEY_OUT_S3 = \"IHS/ship_data.csv\"\n",
    "FILE_PATH_OUT_S3 = BUCKET_OUT + \"/\" + FILE_KEY_OUT_S3\n",
    "\n",
    "with fs.open(FILE_PATH_OUT_S3, 'w') as file_out:\n",
    "    ship_data.to_csv(file_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff1bd1-14f6-4e2a-bbf9-d113ba1cca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second file read ship codes\n",
    "df_ship_code = spark.read.load(basepath + \"tblShipTypeCodes.CSV\", \n",
    "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "\n",
    "df_ship_code.printSchema()\n",
    "\n",
    "# select only relevant cols from spark df\n",
    "ship_code = df_ship_code.select(\"StatCode5\", \"ShipTypeLevel1\", \"ShipTypeLevel2\", \"ShipTypeLevel3\", \"ShipTypeLevel4\", \"ShipTypeLevel5\", \n",
    "                                \"SubGroup\", \"SubType\").toPandas()\n",
    "\n",
    "print('Loading tblShipTypeCodes.csv (few cols) ....')\n",
    "ship_code.shape\n",
    "ship_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80b312bf-968f-4b46-936d-0ee5b4f5ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_KEY_OUT_S3 = \"IHS/ship_codes.csv\"\n",
    "FILE_PATH_OUT_S3 = BUCKET_OUT + \"/\" + FILE_KEY_OUT_S3\n",
    "\n",
    "with fs.open(FILE_PATH_OUT_S3, 'w') as file_out:\n",
    "    ship_code.to_csv(file_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f66697-ce7c-49c6-9b98-5342cf290ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Config template datadive",
   "language": "python3",
   "name": "datadive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
